# ğŸ¯ YouTube Video Summarizer â€” Lab 1 (Tips Hindawi LLLs Training)

## ğŸ“– Overview

This project was developed as part of **Tips Hindawi LLLs Training â€“ Lab 1**.
The objective was to build a Python program capable of:

1. Taking a YouTube video link as input
2. Automatically extracting the videoâ€™s transcript
3. Summarizing the transcript into a concise, readable paragraph

This project introduces key skills in:

* API usage
* Natural Language Processing (NLP)
* Text summarization using pre-trained models

---

## âš™ï¸ Features

âœ… Extracts YouTube video ID from any valid URL format
âœ… Fetches the transcript using **YouTubeTranscriptApi**
âœ… Splits long transcripts into smaller chunks to handle model limits
âœ… Summarizes each chunk and combines them into a final summary
âœ… Runs smoothly on **CPU or GPU (Kaggle)** environments

---

## ğŸ§© Project Structure

```
â”œâ”€â”€ lap-1.ipynb        # Jupyter Notebook containing the full implementation
â”œâ”€â”€ Lab_1.pdf          # Task description document
â”œâ”€â”€ README.md          # (this file)
```

---

## ğŸš€ Installation & Setup

### 1. Clone or open in Kaggle / Colab

If using Kaggle, just upload the `.ipynb` file and run all cells.

Or, to run locally:

```bash
git clone <your-repo-link>
cd youtube-summarizer
```

### 2. Install dependencies

```bash
pip install youtube-transcript-api transformers torch
```

*(If you face CUDA issues on Kaggle, the code automatically switches to CPU.)*

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Extract the Video ID

```python
from urllib.parse import urlparse, parse_qs

def extract_video_id(url: str) -> str:
    parsed = urlparse(url)
    qs = parse_qs(parsed.query)
    if 'v' in qs:
        return qs['v'][0]
    if parsed.netloc in ['youtu.be', 'www.youtu.be']:
        return parsed.path.lstrip('/')
    raise ValueError(f"No video id found in URL: {url}")
```

### 2ï¸âƒ£ Fetch the Transcript

```python
from youtube_transcript_api import YouTubeTranscriptApi
transcript = YouTubeTranscriptApi().fetch(video_id, languages=['en'])
text = " ".join(snippet["text"] for snippet in transcript)
```

### 3ï¸âƒ£ Summarize the Transcript

```python
from transformers import pipeline
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

summary = summarizer(text, max_length=200, min_length=50, do_sample=False)
print(summary[0]["summary_text"])
```

---

## âš¡ Advanced: Chunking for Long Videos

Large transcripts can exceed the modelâ€™s token limit.
To handle this, the text is split into smaller **chunks**:

```python
def chunk_text(text, max_chars=2500):
    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]
```

Each chunk is summarized separately and then combined into one final summary.

---

## ğŸ§¾ Example Output

**Input:**
`https://youtu.be/vStJoetOxJg`

**Output Example:**

```
The video discusses the process of creating AI-based text summarizers.
It explains how to use APIs, extract transcripts, and generate meaningful
summaries using pre-trained transformer models.
```

---

## ğŸ§° Technologies Used

* **Python 3**
* **Transformers (Hugging Face)**
* **YouTube Transcript API**
* **Torch (PyTorch backend)**

---

## ğŸ’» Environment

* Developed and tested on **Kaggle GPU (Tesla T4)**
* Works on **Google Colab** and local environments as well

---

## ğŸ§‘â€ğŸ“ Author

**Abdallah Elhoseny**
AI Engineer | Tips Hindawi LLLs Trainee